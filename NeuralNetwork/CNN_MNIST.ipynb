{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cWllzc432KmX",
        "outputId": "a6152622-efca-4f21-a62a-856d8bca6102"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n",
            "\u001b[1m11490434/11490434\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0us/step\n",
            "x_train shape: (60000, 28, 28)\n",
            "y_train shape: (60000,)\n",
            "x_test shape: (10000, 28, 28)\n",
            "y_test shape: (10000,)\n"
          ]
        }
      ],
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "\n",
        "(x_train, y_train), (x_test, y_test) = tf.keras.datasets.mnist.load_data()\n",
        "x_train, x_test = x_train / 255.0, x_test / 255.0\n",
        "print(f'x_train shape: {x_train.shape}')\n",
        "print(f'y_train shape: {y_train.shape}')\n",
        "print(f'x_test shape: {x_test.shape}')\n",
        "print(f'y_test shape: {y_test.shape}')\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# from tensorflow.keras.models import Sequential\n",
        "# from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout\n",
        "\n",
        "# model = Sequential([\n",
        "#     # Add Convolutional layers\n",
        "#     Conv2D(32, (3, 3), activation='relu', input_shape=(28, 28, 1)),\n",
        "#     MaxPooling2D((2, 2)),\n",
        "\n",
        "#     # Another convolutional layer\n",
        "#     Conv2D(64, (3, 3), activation='relu'),\n",
        "#     MaxPooling2D((2, 2)),\n",
        "\n",
        "#     # Flatten the feature maps into a 1D vector\n",
        "#     Flatten(),\n",
        "\n",
        "#     # Fully connected layers\n",
        "#     Dense(128, activation='relu'),\n",
        "#     Dropout(0.5),  # Add dropout to prevent overfitting\n",
        "#     Dense(10, activation='softmax')  # Output layer\n",
        "# ])\n",
        "\n",
        "# # Compile the model\n",
        "# model.compile(\n",
        "#     optimizer='adam',\n",
        "#     loss='sparse_categorical_crossentropy',\n",
        "#     metrics=['accuracy']\n",
        "# )\n",
        "\n",
        "# # Train the model\n",
        "# model.fit(x_train, y_train, epochs=10, batch_size=64)\n",
        "\n",
        "# # Evaluate the model\n",
        "# test_loss, test_acc = model.evaluate(x_test, y_test)\n",
        "# print(f'Test accuracy: {test_acc}')\n"
      ],
      "metadata": {
        "id": "-DQmkKaZ2Lk4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ecd2b16a-a6e4-4b5a-e518-98d0f4d4f810"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/convolutional/base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m60s\u001b[0m 61ms/step - accuracy: 0.8421 - loss: 0.5001\n",
            "Epoch 2/10\n",
            "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m56s\u001b[0m 60ms/step - accuracy: 0.9731 - loss: 0.0929\n",
            "Epoch 3/10\n",
            "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m80s\u001b[0m 58ms/step - accuracy: 0.9809 - loss: 0.0632\n",
            "Epoch 4/10\n",
            "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m82s\u001b[0m 57ms/step - accuracy: 0.9852 - loss: 0.0502\n",
            "Epoch 5/10\n",
            "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m81s\u001b[0m 56ms/step - accuracy: 0.9886 - loss: 0.0398\n",
            "Epoch 6/10\n",
            "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m53s\u001b[0m 56ms/step - accuracy: 0.9895 - loss: 0.0346\n",
            "Epoch 7/10\n",
            "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m52s\u001b[0m 56ms/step - accuracy: 0.9901 - loss: 0.0318\n",
            "Epoch 8/10\n",
            "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m83s\u001b[0m 57ms/step - accuracy: 0.9916 - loss: 0.0283\n",
            "Epoch 9/10\n",
            "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m53s\u001b[0m 56ms/step - accuracy: 0.9925 - loss: 0.0225\n",
            "Epoch 10/10\n",
            "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m82s\u001b[0m 57ms/step - accuracy: 0.9934 - loss: 0.0209\n",
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 9ms/step - accuracy: 0.9907 - loss: 0.0271\n",
            "Test accuracy: 0.9929999709129333\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout, BatchNormalization\n",
        "\n",
        "model = Sequential([\n",
        "\n",
        "    # First convolutional block\n",
        "    Conv2D(32, (3, 3), activation='relu', input_shape=(28, 28, 1)),\n",
        "    BatchNormalization(),  # Add batch normalization for faster convergence\n",
        "    MaxPooling2D((2, 2)),\n",
        "\n",
        "    # Second convolutional block\n",
        "    Conv2D(64, (3, 3), activation='relu'),\n",
        "    BatchNormalization(),\n",
        "    MaxPooling2D((2, 2)),\n",
        "\n",
        "    # Third convolutional block with more filters\n",
        "    Conv2D(128, (3, 3), activation='relu'),\n",
        "    BatchNormalization(),\n",
        "    MaxPooling2D((2, 2)),\n",
        "\n",
        "    # Flattening the feature maps\n",
        "    Flatten(),\n",
        "\n",
        "    # Fully connected layer with more neurons\n",
        "    Dense(256, activation='relu'),\n",
        "    Dropout(0.5),  # Dropout for regularization to reduce overfitting\n",
        "\n",
        "    # Another fully connected layer\n",
        "    Dense(128, activation='relu'),\n",
        "    Dropout(0.5),\n",
        "\n",
        "    # Output layer\n",
        "    Dense(10, activation='softmax')  # For multi-class classification\n",
        "])\n",
        "\n",
        "# Compile the model\n",
        "model.compile(\n",
        "    optimizer='adam',\n",
        "    loss='sparse_categorical_crossentropy',\n",
        "    metrics=['accuracy']\n",
        ")\n",
        "\n",
        "# Train the model\n",
        "model.fit(x_train, y_train, epochs=15, batch_size=64)\n",
        "\n",
        "# Evaluate the model\n",
        "test_loss, test_acc = model.evaluate(x_test, y_test)\n",
        "print(f'Test accuracy: {test_acc}')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kg36fsYKoVnX",
        "outputId": "00bf1971-ef11-40a2-9f1f-f3a214f2bd03"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/15\n",
            "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m89s\u001b[0m 91ms/step - accuracy: 0.8033 - loss: 0.6349\n",
            "Epoch 2/15\n",
            "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m142s\u001b[0m 91ms/step - accuracy: 0.9719 - loss: 0.1021\n",
            "Epoch 3/15\n",
            "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m86s\u001b[0m 92ms/step - accuracy: 0.9811 - loss: 0.0714\n",
            "Epoch 4/15\n",
            "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m89s\u001b[0m 95ms/step - accuracy: 0.9838 - loss: 0.0570\n",
            "Epoch 5/15\n",
            "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m142s\u001b[0m 94ms/step - accuracy: 0.9852 - loss: 0.0546\n",
            "Epoch 6/15\n",
            "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m139s\u001b[0m 91ms/step - accuracy: 0.9886 - loss: 0.0393\n",
            "Epoch 7/15\n",
            "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m87s\u001b[0m 92ms/step - accuracy: 0.9890 - loss: 0.0401\n",
            "Epoch 8/15\n",
            "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m143s\u001b[0m 93ms/step - accuracy: 0.9912 - loss: 0.0301\n",
            "Epoch 9/15\n",
            "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m140s\u001b[0m 91ms/step - accuracy: 0.9916 - loss: 0.0305\n",
            "Epoch 10/15\n",
            "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m85s\u001b[0m 90ms/step - accuracy: 0.9927 - loss: 0.0282\n",
            "Epoch 11/15\n",
            "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m86s\u001b[0m 91ms/step - accuracy: 0.9918 - loss: 0.0296\n",
            "Epoch 12/15\n",
            "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m143s\u001b[0m 93ms/step - accuracy: 0.9934 - loss: 0.0235\n",
            "Epoch 13/15\n",
            "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m88s\u001b[0m 93ms/step - accuracy: 0.9942 - loss: 0.0226\n",
            "Epoch 14/15\n",
            "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m87s\u001b[0m 93ms/step - accuracy: 0.9947 - loss: 0.0173\n",
            "Epoch 15/15\n",
            "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m142s\u001b[0m 92ms/step - accuracy: 0.9943 - loss: 0.0203\n",
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 12ms/step - accuracy: 0.9857 - loss: 0.0790\n",
            "Test accuracy: 0.9891999959945679\n"
          ]
        }
      ]
    }
  ]
}